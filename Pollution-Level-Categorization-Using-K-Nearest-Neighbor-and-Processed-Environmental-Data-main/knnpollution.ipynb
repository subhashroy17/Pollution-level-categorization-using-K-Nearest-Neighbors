{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b948ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with shape: (5000, 10)\n",
      "Automatically selected features: ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'Humidity', 'Temperature']\n",
      "Creating Category using PM2.5 thresholds on column: PM2.5\n",
      "Using label column: Category\n",
      "Category\n",
      "0    3956\n",
      "1     713\n",
      "2     215\n",
      "3      68\n",
      "4      48\n",
      "Name: count, dtype: int64\n",
      "Feature columns used: ['PM2.5', 'PM10', 'NO2', 'SO2', 'CO', 'Humidity', 'Temperature']\n",
      "Target distribution:\n",
      " Category\n",
      "0    3956\n",
      "1     713\n",
      "2     215\n",
      "3      68\n",
      "4      48\n",
      "Name: count, dtype: int64\n",
      "Train shape: (4000, 7) Test shape: (1000, 7)\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best params: {'knn__n_neighbors': 7, 'knn__p': 1, 'knn__weights': 'distance'}\n",
      "Best CV accuracy: 0.96275\n",
      "Test Accuracy: 0.966\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       791\n",
      "           1       0.91      0.87      0.89       143\n",
      "           2       0.88      0.88      0.88        43\n",
      "           3       0.92      0.79      0.85        14\n",
      "           4       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.94      0.88      0.91      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Saved confusion matrix to plots\\confusion_matrix.png\n",
      "Saved ROC curves to plots\\roc_curves.png\n",
      "Saved correlation heatmap to plots\\correlation_heatmap.png\n",
      "Saved feature distributions to plots\\feature_distributions.png\n",
      "Saved pairplot to plots\\pairplot.png\n",
      "Saved PCA plots to plots\\pca_explained_variance.png and plots\\pca_2d.png\n",
      "Saved t-SNE plot to plots\\tsne_2d.png\n",
      "Saved grid search results to plots\\grid_search_results.png\n",
      "Saved permutation importance to plots\\permutation_importance.png\n",
      "Saved trained model to knn_pollution_model.joblib\n",
      "\n",
      "Example prediction (median values):\n",
      "{'PM2.5': 12.0, 'PM10': 21.7, 'NO2': 25.3, 'SO2': 8.0, 'CO': 1.41, 'Humidity': 69.8, 'Temperature': 29.0}\n",
      "{'predicted_category': 0, 'meaning': 'Good'}\n",
      "\n",
      "Example prediction (high pollution sample - 95th percentile):\n",
      "{'PM2.5': np.float64(68.4), 'PM10': np.float64(84.70500000000003), 'NO2': np.float64(43.1), 'SO2': np.float64(23.6), 'CO': np.float64(2.53), 'Humidity': np.float64(97.90500000000003), 'Temperature': np.float64(42.6)}\n",
      "{'predicted_category': 2, 'meaning': 'Poor'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.inspection import permutation_importance\n",
    "import joblib\n",
    "\n",
    "DATA_PATH = \"updated_pollution_dataset.csv\"\n",
    "MODEL_PATH = \"knn_pollution_model.joblib\"\n",
    "PLOTS_DIR = \"plots\"\n",
    "\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def load_dataset(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Dataset not found at {path}. Please provide a CSV.\")\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Loaded dataset with shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "def auto_select_features(df):\n",
    "    candidate_features = [\n",
    "        \"PM2.5\", \"PM2_5\", \"PM25\", \"PM10\", \"NO2\", \"NO_2\", \"SO2\", \"SO_2\",\n",
    "        \"CO\", \"O3\", \"O_3\", \"AQI\", \"Humidity\", \"Temperature\", \"RH\", \"Temp\"\n",
    "    ]\n",
    "    lower_map = {c.lower(): c for c in df.columns}\n",
    "    chosen_features = []\n",
    "    for cand in candidate_features:\n",
    "        key = cand.lower()\n",
    "        if key in lower_map:\n",
    "            chosen_features.append(lower_map[key])\n",
    "    if len(chosen_features) == 0:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        exclude = [c for c in numeric_cols if 'id' in c.lower() or 'time' in c.lower() or 'date' in c.lower()]\n",
    "        chosen_features = [c for c in numeric_cols if c not in exclude]\n",
    "    return chosen_features\n",
    "\n",
    "def prepare_label(df):\n",
    "    possible_label_names = [\"Category\", \"category\", \"Label\", \"label\", \"PollutionLevel\", \"pollution_level\", \"AQI_Category\"]\n",
    "    for name in possible_label_names:\n",
    "        if name in df.columns:\n",
    "            print(\"Found label column:\", name)\n",
    "            return df, name\n",
    "\n",
    "    aqi_candidates = [c for c in df.columns if c.lower() == \"aqi\"]\n",
    "    if len(aqi_candidates) > 0:\n",
    "        aqi_col = aqi_candidates[0]\n",
    "        print(\"Using AQI column to create categories:\", aqi_col)\n",
    "        def aqi_to_cat(a):\n",
    "            if pd.isna(a):\n",
    "                return np.nan\n",
    "            a = float(a)\n",
    "            if a <= 50:\n",
    "                return 0\n",
    "            elif a <= 100:\n",
    "                return 1\n",
    "            elif a <= 150:\n",
    "                return 2\n",
    "            elif a <= 200:\n",
    "                return 3\n",
    "            else:\n",
    "                return 4\n",
    "        df[\"Category\"] = df[aqi_col].apply(aqi_to_cat)\n",
    "        return df, \"Category\"\n",
    "\n",
    "    pm25_candidates = [c for c in df.columns if c.lower() in (\"pm2.5\", \"pm2_5\", \"pm25\", \"pm2.5 (Âµg/m3)\")]\n",
    "    if len(pm25_candidates) > 0:\n",
    "        pm25 = pm25_candidates[0]\n",
    "        print(\"Creating Category using PM2.5 thresholds on column:\", pm25)\n",
    "        def pm25_to_cat(v):\n",
    "            if pd.isna(v):\n",
    "                return np.nan\n",
    "            v = float(v)\n",
    "            if v <= 30:\n",
    "                return 0\n",
    "            elif v <= 60:\n",
    "                return 1\n",
    "            elif v <= 90:\n",
    "                return 2\n",
    "            elif v <= 120:\n",
    "                return 3\n",
    "            else:\n",
    "                return 4\n",
    "        df[\"Category\"] = df[pm25].apply(pm25_to_cat)\n",
    "        return df, \"Category\"\n",
    "\n",
    "    raise ValueError(\"Could not determine or create a label column. Ensure CSV has 'Category' or 'AQI' or PM2.5.\")\n",
    "\n",
    "def build_and_train(X_train, y_train, param_grid=None):\n",
    "    pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"knn\", KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"knn__n_neighbors\": list(range(1, 16, 2)),\n",
    "            \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "            \"knn__p\": [1, 2]\n",
    "        }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=1, return_train_score=True)\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best params:\", grid.best_params_)\n",
    "    print(\"Best CV accuracy:\", grid.best_score_)\n",
    "    return grid.best_estimator_, grid\n",
    "\n",
    "def plot_correlation_heatmap(X, outpath=os.path.join(PLOTS_DIR, \"correlation_heatmap.png\")):\n",
    "    corr = X.corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\", square=True)\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved correlation heatmap to\", outpath)\n",
    "\n",
    "def plot_feature_distributions(X, y=None, outpath=os.path.join(PLOTS_DIR, \"feature_distributions.png\")):\n",
    "    n_cols = 3\n",
    "    n_features = X.shape[1]\n",
    "    n_rows = int(np.ceil(n_features / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols*5, n_rows*3.5))\n",
    "    axes = axes.flatten()\n",
    "    for i, col in enumerate(X.columns):\n",
    "        ax = axes[i]\n",
    "        sns.histplot(X[col].dropna(), kde=True, ax=ax)\n",
    "        ax.set_title(col)\n",
    "    # remove unused axes\n",
    "    for j in range(n_features, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved feature distributions to\", outpath)\n",
    "\n",
    "def plot_pairplot(X, y, max_features=6, outpath=os.path.join(PLOTS_DIR, \"pairplot.png\")):\n",
    "    # limit to a few features to keep plot readable\n",
    "    use_cols = list(X.columns[:max_features])\n",
    "    df_small = pd.concat([X[use_cols], pd.Series(y, name=\"label\")], axis=1)\n",
    "    sns.pairplot(df_small, hue=\"label\", corner=True, plot_kws={\"alpha\":0.6, \"s\":30})\n",
    "    plt.suptitle(\"Pairplot (first {} features)\".format(len(use_cols)), y=1.02)\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved pairplot to\", outpath)\n",
    "\n",
    "def plot_pca(X, y, outpath_exp=os.path.join(PLOTS_DIR, \"pca_explained_variance.png\"),\n",
    "             outpath_2d=os.path.join(PLOTS_DIR, \"pca_2d.png\")):\n",
    "    imputed = SimpleImputer(strategy=\"mean\").fit_transform(X)\n",
    "    scaled = StandardScaler().fit_transform(imputed)\n",
    "    pca = PCA(n_components=min(10, scaled.shape[1]))\n",
    "    comps = pca.fit_transform(scaled)\n",
    "    # explained variance plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(np.arange(1, len(pca.explained_variance_ratio_)+1), np.cumsum(pca.explained_variance_ratio_)*100, marker='o')\n",
    "    plt.xlabel(\"Number of components\")\n",
    "    plt.ylabel(\"Cumulative explained variance (%)\")\n",
    "    plt.title(\"PCA cumulative explained variance\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath_exp, dpi=300)\n",
    "    plt.close()\n",
    "    # 2D scatter\n",
    "    if comps.shape[1] >= 2:\n",
    "        plt.figure(figsize=(7,6))\n",
    "        sns.scatterplot(x=comps[:,0], y=comps[:,1], hue=y, palette=\"tab10\", alpha=0.8)\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.title(\"PCA 2D projection colored by class\")\n",
    "        plt.legend(title=\"label\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outpath_2d, dpi=300)\n",
    "        plt.close()\n",
    "        print(\"Saved PCA plots to\", outpath_exp, \"and\", outpath_2d)\n",
    "    else:\n",
    "        print(\"Not enough PCA components for 2D plot; saved explained variance only.\")\n",
    "\n",
    "def plot_tsne(X, y, outpath=os.path.join(PLOTS_DIR, \"tsne_2d.png\")):\n",
    "    try:\n",
    "        imputed = SimpleImputer(strategy=\"mean\").fit_transform(X)\n",
    "        scaled = StandardScaler().fit_transform(imputed)\n",
    "        tsne = TSNE(n_components=2, random_state=42, init=\"pca\", learning_rate=\"auto\")\n",
    "        embed = tsne.fit_transform(scaled)\n",
    "        plt.figure(figsize=(7,6))\n",
    "        sns.scatterplot(x=embed[:,0], y=embed[:,1], hue=y, palette=\"tab10\", alpha=0.8)\n",
    "        plt.title(\"t-SNE 2D embedding\")\n",
    "        plt.legend(title=\"label\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outpath, dpi=300)\n",
    "        plt.close()\n",
    "        print(\"Saved t-SNE plot to\", outpath)\n",
    "    except Exception as e:\n",
    "        print(\"t-SNE plotting failed:\", e)\n",
    "\n",
    "def plot_grid_search_results(grid, outpath=os.path.join(PLOTS_DIR, \"grid_search_results.png\")):\n",
    "    # Attempt to plot mean test score for different n_neighbors (aggregated)\n",
    "    try:\n",
    "        res = pd.DataFrame(grid.cv_results_)\n",
    "        # Extract n_neighbors if present in param_knn__n_neighbors\n",
    "        if 'param_knn__n_neighbors' in res.columns:\n",
    "            summary = res.groupby('param_knn__n_neighbors')['mean_test_score'].mean().reset_index()\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(summary['param_knn__n_neighbors'], summary['mean_test_score'], marker='o')\n",
    "            plt.xlabel(\"n_neighbors\")\n",
    "            plt.ylabel(\"Mean CV accuracy\")\n",
    "            plt.title(\"CV accuracy vs n_neighbors\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(outpath, dpi=300)\n",
    "            plt.close()\n",
    "            print(\"Saved grid search results to\", outpath)\n",
    "        else:\n",
    "            print(\"GridSearch results do not contain 'param_knn__n_neighbors', skipping grid plot.\")\n",
    "    except Exception as e:\n",
    "        print(\"Grid search plotting failed:\", e)\n",
    "\n",
    "def plot_confusion_matrix(cm, labels, outpath=os.path.join(PLOTS_DIR, \"confusion_matrix.png\")):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(outpath, dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Saved confusion matrix to\", outpath)\n",
    "\n",
    "def plot_roc_multiclass(model, X_test, y_test, outpath=os.path.join(PLOTS_DIR, \"roc_curves.png\")):\n",
    "    # Only possible if probability estimates available\n",
    "    try:\n",
    "        if not hasattr(model, \"predict_proba\"):\n",
    "            print(\"Model doesn't support predict_proba; skipping ROC curves.\")\n",
    "            return\n",
    "        imputed = SimpleImputer(strategy=\"mean\").fit_transform(X_test)\n",
    "        scaled = StandardScaler().fit_transform(imputed)\n",
    "        y_score = model.predict_proba(X_test)\n",
    "        classes = np.unique(y_test)\n",
    "        n_classes = len(classes)\n",
    "        # Binarize labels\n",
    "        y_bin = label_binarize(y_test, classes=classes)\n",
    "        plt.figure(figsize=(8,6))\n",
    "        fprs = []\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        for i in range(n_classes):\n",
    "            fpr, tpr, _ = roc_curve(y_bin[:,i], y_score[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            plt.plot(fpr, tpr, lw=2, label=f\"Class {classes[i]} (AUC = {roc_auc:.2f})\")\n",
    "            fprs.append(fpr); tprs.append(tpr); aucs.append(roc_auc)\n",
    "        # micro-average\n",
    "        y_bin_flat = y_bin.ravel()\n",
    "        y_score_flat = y_score.ravel()\n",
    "        # skip micro/macro for now if shapes mismatch\n",
    "        plt.plot([0,1], [0,1], linestyle='--', color='grey')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"Multiclass ROC Curves\")\n",
    "        plt.legend(loc=\"lower right\", bbox_to_anchor=(1.05, 0))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outpath, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"Saved ROC curves to\", outpath)\n",
    "    except Exception as e:\n",
    "        print(\"ROC plotting failed:\", e)\n",
    "\n",
    "def plot_permutation_importance(model, X_val, y_val, outpath=os.path.join(PLOTS_DIR, \"permutation_importance.png\"), n_repeats=10):\n",
    "    try:\n",
    "        # Need a pipeline to pass through the same preprocessing used for training if model is pipeline\n",
    "        from sklearn.inspection import permutation_importance\n",
    "        result = permutation_importance(model, X_val, y_val, n_repeats=n_repeats, random_state=42, n_jobs=-1)\n",
    "        sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "        names = np.array(X_val.columns)[sorted_idx]\n",
    "        means = result.importances_mean[sorted_idx]\n",
    "        stds = result.importances_std[sorted_idx]\n",
    "        plt.figure(figsize=(8, max(4, 0.4 * len(names))))\n",
    "        plt.barh(names, means, xerr=stds)\n",
    "        plt.xlabel(\"Permutation importance (mean decrease in score)\")\n",
    "        plt.title(\"Permutation Feature Importance\")\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outpath, dpi=300)\n",
    "        plt.close()\n",
    "        print(\"Saved permutation importance to\", outpath)\n",
    "    except Exception as e:\n",
    "        print(\"Permutation importance failed:\", e)\n",
    "\n",
    "def evaluate_and_plot(model, X_test, y_test, features):\n",
    "    # Prediction + basic metrics\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test Accuracy:\", acc)\n",
    "    print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # save confusion matrix plot\n",
    "    labels = np.unique(pd.concat([y_test, pd.Series(y_pred)]))\n",
    "    plot_confusion_matrix(cm, labels)\n",
    "    # ROC (if available)\n",
    "    try:\n",
    "        plot_roc_multiclass(model, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(\"ROC plotting exception:\", e)\n",
    "    return acc, cm\n",
    "\n",
    "def main():\n",
    "    df = load_dataset(DATA_PATH)\n",
    "    chosen_features = auto_select_features(df)\n",
    "    print(\"Automatically selected features:\", chosen_features)\n",
    "    if len(chosen_features) < 2:\n",
    "        raise ValueError(\"Too few numeric features detected.\")\n",
    "\n",
    "    df, label_col = prepare_label(df)\n",
    "    print(\"Using label column:\", label_col)\n",
    "    print(df[label_col].value_counts(dropna=False))\n",
    "\n",
    "    df = df.dropna(subset=[label_col]).reset_index(drop=True)\n",
    "\n",
    "    features = [f for f in chosen_features if f != label_col and f in df.columns]\n",
    "    X = df[features].copy()\n",
    "    y = df[label_col].astype(int).copy()\n",
    "\n",
    "    print(\"Feature columns used:\", features)\n",
    "    print(\"Target distribution:\\n\", y.value_counts())\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "    print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
    "\n",
    "    # Train\n",
    "    best_model, grid = build_and_train(X_train, y_train)\n",
    "\n",
    "    # Evaluate & plot confusion matrix + ROC\n",
    "    acc, cm = evaluate_and_plot(best_model, X_test, y_test, features)\n",
    "\n",
    "    # Additional plots for paper\n",
    "    try:\n",
    "        plot_correlation_heatmap(X)\n",
    "    except Exception as e:\n",
    "        print(\"Correlation heatmap error:\", e)\n",
    "\n",
    "    try:\n",
    "        plot_feature_distributions(X, y)\n",
    "    except Exception as e:\n",
    "        print(\"Feature distribution error:\", e)\n",
    "\n",
    "    try:\n",
    "        plot_pairplot(X, y, max_features=6)\n",
    "    except Exception as e:\n",
    "        print(\"Pairplot error:\", e)\n",
    "\n",
    "    try:\n",
    "        plot_pca(X, y)\n",
    "    except Exception as e:\n",
    "        print(\"PCA plotting error:\", e)\n",
    "\n",
    "    try:\n",
    "        plot_tsne(X, y)\n",
    "    except Exception as e:\n",
    "        print(\"t-SNE/UMAP error:\", e)\n",
    "\n",
    "    try:\n",
    "        plot_grid_search_results(grid)\n",
    "    except Exception as e:\n",
    "        print(\"Grid search plot error:\", e)\n",
    "\n",
    "    try:\n",
    "        plot_permutation_importance(best_model, X_test, y_test)\n",
    "    except Exception as e:\n",
    "        print(\"Permutation importance error:\", e)\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(best_model, MODEL_PATH)\n",
    "    print(f\"Saved trained model to {MODEL_PATH}\")\n",
    "\n",
    "    # Example predictions (median / 95th percentile)\n",
    "    median_vals = X.median().to_dict()\n",
    "    high_vals = {k: (X[k].quantile(0.95) if np.isfinite(X[k].quantile(0.95)) else X[k].max()) for k in X.columns}\n",
    "\n",
    "    def predict_pollution(sample_dict):\n",
    "        sample = pd.DataFrame([sample_dict], columns=features)\n",
    "        pred = best_model.predict(sample)[0]\n",
    "        meaning = {0: \"Good\", 1: \"Moderate\", 2: \"Poor\", 3: \"Very Poor\", 4: \"Severe\"}.get(pred, str(pred))\n",
    "        return {\"predicted_category\": int(pred), \"meaning\": meaning}\n",
    "\n",
    "    print(\"\\nExample prediction (median values):\")\n",
    "    print(median_vals)\n",
    "    print(predict_pollution(median_vals))\n",
    "\n",
    "    print(\"\\nExample prediction (high pollution sample - 95th percentile):\")\n",
    "    print(high_vals)\n",
    "    print(predict_pollution(high_vals))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
